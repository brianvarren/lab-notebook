
Today is a really exciting and important day for me, because I’m working on the Lung Loop Sampler—an idea that has evolved through several iterations, starting as a Reactor instrument I fell in love with, and now finally finding its way into hardware form, where it feels like it’s becoming real in a way it never quite was on a screen. The milestone that makes today different is the waveform view on the display finally coming to life: a wide 256×64 window that feels perfectly built for this job, capable of showing samples in real time, complete with loop points, updated boundaries, and the playback head moving across the field, all the things I’ve been imagining since this idea first took hold.

Getting here has meant building up subsystems one at a time—the display driver, the encoder and menu system—and now the module boots, runs its load sequence, indexes the SD card, and presents a file list I can scroll through with the encoder, smooth and intuitive, the kind of interaction that feels good in the fingers. Clicking loads a file, and from there the chain of processing begins: peak detection, normalization to –3 dB, conversion into Q15 fixed-point so the data is ready for efficient manipulation, then scaled down to 12-bit just before PWM output. It’s a careful balance between preserving fidelity and keeping things light enough to run, and while PWM output is a compromise, it’s also fast, cheap, and good enough to start making music without waiting for the more complex codec path that will come later, when stereo output and higher quality become the goal.

The codebase itself has grown into something larger and more structured than any project I’ve done before—about twenty-five source files now, each a few hundred lines, compared to maybe seven hundred lines total in earlier modules. The main sketch is under three hundred lines, while the rest is divided into pieces that keep the system modular and easy to navigate, which not only helps me but also shapes how I work with AI. Instead of forcing a model to digest the whole thousand-line project, I can hand it just the parts relevant to what I’m building, which keeps the process clear and avoids hitting the limits of context. And by switching back and forth between GPT and Claude, I’ve found a rhythm—pushing one model until drift and errors creep in, then handing the clean subset over to the other, letting each one see things the other missed. It’s like passing ideas between two sharp but differently tuned minds, and the results add up to more than either one could produce alone.

So this moment—seeing the waveform draw itself on the display—isn’t just a technical checkpoint, it’s proof that the architecture holds, that the way I’ve divided the code and leaned on the tools is working, and that Lung is crossing the line between an idea I’ve been nurturing and an instrument I can actually hold in my hands.

---

I had to take my DACless library, which handled PWM audio output and ADC reading on RP2040 boards, and decided it was time to separate ADC reading from PWM output. I’m at a crossroads now: I have a working waveform and a menu system in the loop sampler, but the next step is getting ADC values in. That means wiring up the potentiometers and the FlexCV inputs, which combine and bias a jack with a knob for loop start and loop length.

Once loop start and loop length ADC inputs are in place, I can implement a loop boundary on the display. The idea is to draw a rounded rectangular box around a selected loop zone, dim everything outside it, and show the playback head moving inside the loop to make it clear where looping is happening.

I didn’t want to throw the whole DACless library in yet, and this made me realize something: if I eventually build a dedicated stereo audio codec board—a hat, or even a custom RP2350B board with an onboard codec—I’ll still want the built-in 8 ADCs for things like knob reads. For that kind of use, precision and noise aren’t critical. But if I’m using a codec, I won’t need PWM output anymore. Having both PWM and ADC combined in the same library doesn’t make sense.

So the split is necessary: DACless will now be strictly PWM output. ADC will live in its own library. Claude has been calling this “ADC Capture,” which is fine, though I had hoped for something like “ADC-less” to parallel DACless—meaning, no dedicated ADC chip, just the built-ins. Either way, it’s not a big deal. I can batch rename later if I want.

This is a big step, because it sets me up to get loop points on the display and watch them update in real time as the knobs move. That’s going to be exciting.